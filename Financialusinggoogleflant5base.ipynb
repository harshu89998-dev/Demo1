{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkMizxJ+SsqORxiBzLcumu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "267MbwNKr2yt"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# üß† SMART FINANCIAL ADVISOR (FLAN-T5 + LoRA)\n",
        "# ==========================================\n",
        "\n",
        "# 1Ô∏è‚É£ Install dependencies\n",
        "!pip install -q transformers datasets peft accelerate bitsandbytes flask pyngrok torch sentencepiece\n",
        "\n",
        "# 2Ô∏è‚É£ Imports & GPU check\n",
        "import torch, os\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 3Ô∏è‚É£ Load tokenizer & base model\n",
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "# 4Ô∏è‚É£ Create small financial Q&A + summarization dataset\n",
        "data = {\n",
        "    \"instruction\": [\n",
        "        \"Explain SIP in simple terms\",\n",
        "        \"What is credit score?\",\n",
        "        \"How can someone improve financial health?\",\n",
        "        \"Summarize this: Systematic Investment Plan allows regular investment in mutual funds over time.\"\n",
        "    ],\n",
        "    \"response\": [\n",
        "        \"SIP means investing a fixed amount regularly in mutual funds to build wealth gradually.\",\n",
        "        \"A credit score is a number that shows how likely a person is to repay loans on time.\",\n",
        "        \"To improve financial health, track expenses, save regularly, invest wisely, and avoid high debt.\",\n",
        "        \"SIP helps people invest small amounts regularly in mutual funds instead of one-time large sums.\"\n",
        "    ]\n",
        "}\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "def preprocess(example):\n",
        "    inputs = [f\"Question: {q}\" for q in example[\"instruction\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=256, truncation=True)\n",
        "    labels = tokenizer(example[\"response\"], max_length=128, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized = dataset.map(preprocess, batched=True)\n",
        "\n",
        "# 5Ô∏è‚É£ Apply LoRA adapters\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\"\n",
        ")\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# 6Ô∏è‚É£ Training setup\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./finetuned_flant5_lora\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    save_strategy=\"no\"\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "# 7Ô∏è‚É£ Test the model\n",
        "def generate_text(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"üß© Sample Tests:\")\n",
        "print(\"Q:\", data[\"instruction\"][0])\n",
        "print(\"A:\", generate_text(\"Question: \" + data[\"instruction\"][0]))\n",
        "print(\"Summary:\", generate_text(\"Summarize: Investing regularly in mutual funds helps build wealth over time.\"))\n",
        "\n",
        "# 8Ô∏è‚É£ Save LoRA model\n",
        "model.save_pretrained(\"smart_financial_advisor_lora\")\n",
        "tokenizer.save_pretrained(\"smart_financial_advisor_lora\")\n",
        "\n",
        "# 9Ô∏è‚É£ Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/ask\", methods=[\"POST\"])\n",
        "def ask():\n",
        "    q = request.json.get(\"question\", \"\")\n",
        "    ans = generate_text(f\"Question: {q}\")\n",
        "    return jsonify({\"answer\": ans})\n",
        "\n",
        "@app.route(\"/summarize\", methods=[\"POST\"])\n",
        "def summarize():\n",
        "    text = request.json.get(\"text\", \"\")\n",
        "    summ = generate_text(f\"Summarize: {text}\")\n",
        "    return jsonify({\"summary\": summ})\n",
        "\n",
        "# 10Ô∏è‚É£ Run with ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"üåê Public URL:\", public_url)\n",
        "app.run(port=5000)"
      ]
    }
  ]
}